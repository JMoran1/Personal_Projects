{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis using an RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /Users/jacobmoran/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n",
      "\u001b[1mDataset imdb_reviews downloaded and prepared to /Users/jacobmoran/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
    "                          as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "\n",
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
      "label:  0\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "  print('text: ', example.numpy())\n",
    "  print('label: ', label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts:  [b\"Are we really making 'video nasties' again? In the guise of a digital wide screen big budget remake of 8MM, this is quite a ride. Unfortunately there is a bit too much story and at times this becomes like a travelogue as our heroine searches the sleaze spots of Paris, Hamburg and Amsterdam. I am however being rather churlish for the 'depraved' scenes, including everything from, hot wax, harsh whipping and rough sex to drowning, beheading and some. These scenes are immaculate and it's a pity Bruno and his budget couldn't stretch to make all the many characterful creatures introduced become more than simply caricatures.\"\n",
      " b'Daphne Zuniga is the only light that shines in this sleepy slasher, and the light fades quickly. If not her, than what other reason to watch this. five college kids are signed up to prepare an old dorm for its due date of demolition. Problems are automatically occurring when a weird homeless man is soliciting, and the group are short a few people. Then, a killer is on the loose. I honestly wanted to say I was going to enjoy this one. It had a fair set up, or maybe that was just Daphne Zuniga in it. The film is too slow, and almost as silent as a library. Most of the acting is below average, and the \"point-of-view\" moments are so old news. Acclaimed composer Christopher Young of such films as \"Hellraiser\" and \"Entrapment\" scored this, in a repetitive cue line that was better made for a TV movie. Still, it seems higher than the movie deserves. So, other than Young and Zuniga, this one scrapes the bottom of the barrel.'\n",
      " b\"FUTZ is the only show preserved from the experimental theatre movement in New York in the 1960s (the origins of Off Off Broadway). Though it's not for everyone, it is a genuinely brilliant, darkly funny, even more often deeply disturbing tale about love, sex, personal liberty, and revenge, a serious morality tale even more relevant now in a time when Congress wants to outlaw gay marriage by trashing our Constitution. The story is not about being gay, though -- it's about love and sex that don't conform to social norms and therefore must be removed through violence and hate. On the surface, it tells the story of a man who falls in love with a pig, but like any great fable, it's not really about animals, it's about something bigger -- stifling conformity in America.<br /><br />The stage version won international acclaim in its original production, it toured the U.S. and Europe, and with others of its kind, influenced almost all theatre that came after it. Luckily, we have preserved here the show pretty much as it was originally conceived, with the original cast and original director, Tom O'Horgan (who also directed HAIR and Jesus Christ Superstar on Broadway).<br /><br />This is not a mainstream, easy-to-take, studio film -- this is an aggressive, unsettling, glorious, deeply emotional, wildly imaginative piece of storytelling that you'll never forget. And it just might change the way you see the world...\"]\n",
      "\n",
      "labels:  [1 0 1]\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "for example, label in train_dataset.take(1):\n",
    "  print('texts: ', example.numpy()[:3])\n",
    "  print()\n",
    "  print('labels: ', label.numpy()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i',\n",
       "       'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but'],\n",
       "      dtype='<U14')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))\n",
    "\n",
    "\n",
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  b\"Are we really making 'video nasties' again? In the guise of a digital wide screen big budget remake of 8MM, this is quite a ride. Unfortunately there is a bit too much story and at times this becomes like a travelogue as our heroine searches the sleaze spots of Paris, Hamburg and Amsterdam. I am however being rather churlish for the 'depraved' scenes, including everything from, hot wax, harsh whipping and rough sex to drowning, beheading and some. These scenes are immaculate and it's a pity Bruno and his budget couldn't stretch to make all the many characterful creatures introduced become more than simply caricatures.\"\n",
      "Round-trip:  are we really making video [UNK] again in the [UNK] of a [UNK] [UNK] screen big budget remake of [UNK] this is quite a [UNK] unfortunately there is a bit too much story and at times this becomes like a [UNK] as our [UNK] [UNK] the [UNK] [UNK] of [UNK] [UNK] and [UNK] i am however being rather [UNK] for the [UNK] scenes including everything from hot [UNK] [UNK] [UNK] and [UNK] sex to [UNK] [UNK] and some these scenes are [UNK] and its a [UNK] [UNK] and his budget couldnt [UNK] to make all the many [UNK] [UNK] [UNK] become more than simply [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
      "\n",
      "Original:  b'Daphne Zuniga is the only light that shines in this sleepy slasher, and the light fades quickly. If not her, than what other reason to watch this. five college kids are signed up to prepare an old dorm for its due date of demolition. Problems are automatically occurring when a weird homeless man is soliciting, and the group are short a few people. Then, a killer is on the loose. I honestly wanted to say I was going to enjoy this one. It had a fair set up, or maybe that was just Daphne Zuniga in it. The film is too slow, and almost as silent as a library. Most of the acting is below average, and the \"point-of-view\" moments are so old news. Acclaimed composer Christopher Young of such films as \"Hellraiser\" and \"Entrapment\" scored this, in a repetitive cue line that was better made for a TV movie. Still, it seems higher than the movie deserves. So, other than Young and Zuniga, this one scrapes the bottom of the barrel.'\n",
      "Round-trip:  [UNK] [UNK] is the only light that [UNK] in this [UNK] [UNK] and the light [UNK] quickly if not her than what other reason to watch this five [UNK] kids are [UNK] up to [UNK] an old [UNK] for its due [UNK] of [UNK] problems are [UNK] [UNK] when a weird [UNK] man is [UNK] and the group are short a few people then a killer is on the [UNK] i [UNK] wanted to say i was going to enjoy this one it had a [UNK] set up or maybe that was just [UNK] [UNK] in it the film is too slow and almost as [UNK] as a [UNK] most of the acting is [UNK] average and the [UNK] moments are so old [UNK] [UNK] [UNK] [UNK] young of such films as [UNK] and [UNK] [UNK] this in a [UNK] [UNK] line that was better made for a tv movie still it seems [UNK] than the movie deserves so other than young and [UNK] this one [UNK] the [UNK] of the [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      "\n",
      "Original:  b\"FUTZ is the only show preserved from the experimental theatre movement in New York in the 1960s (the origins of Off Off Broadway). Though it's not for everyone, it is a genuinely brilliant, darkly funny, even more often deeply disturbing tale about love, sex, personal liberty, and revenge, a serious morality tale even more relevant now in a time when Congress wants to outlaw gay marriage by trashing our Constitution. The story is not about being gay, though -- it's about love and sex that don't conform to social norms and therefore must be removed through violence and hate. On the surface, it tells the story of a man who falls in love with a pig, but like any great fable, it's not really about animals, it's about something bigger -- stifling conformity in America.<br /><br />The stage version won international acclaim in its original production, it toured the U.S. and Europe, and with others of its kind, influenced almost all theatre that came after it. Luckily, we have preserved here the show pretty much as it was originally conceived, with the original cast and original director, Tom O'Horgan (who also directed HAIR and Jesus Christ Superstar on Broadway).<br /><br />This is not a mainstream, easy-to-take, studio film -- this is an aggressive, unsettling, glorious, deeply emotional, wildly imaginative piece of storytelling that you'll never forget. And it just might change the way you see the world...\"\n",
      "Round-trip:  [UNK] is the only show [UNK] from the [UNK] [UNK] [UNK] in new york in the [UNK] the [UNK] of off off [UNK] though its not for everyone it is a [UNK] brilliant [UNK] funny even more often [UNK] [UNK] tale about love sex personal [UNK] and [UNK] a serious [UNK] tale even more [UNK] now in a time when [UNK] wants to [UNK] [UNK] [UNK] by [UNK] our [UNK] the story is not about being [UNK] though its about love and sex that dont [UNK] to [UNK] [UNK] and [UNK] must be [UNK] through violence and hate on the [UNK] it tells the story of a man who falls in love with a [UNK] but like any great [UNK] its not really about [UNK] its about something [UNK] [UNK] [UNK] in [UNK] br the stage version [UNK] [UNK] [UNK] in its original production it [UNK] the us and [UNK] and with others of its kind [UNK] almost all [UNK] that came after it [UNK] we have [UNK] here the show pretty much as it was [UNK] [UNK] with the original cast and original director tom [UNK] who also directed [UNK] and [UNK] [UNK] [UNK] on [UNK] br this is not a [UNK] [UNK] [UNK] film this is an [UNK] [UNK] [UNK] [UNK] emotional [UNK] [UNK] piece of [UNK] that youll never forget and it just might change the way you see the world                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_example = encoder(example)[:3].numpy()\n",
    "encoded_example\n",
    "\n",
    "\n",
    "\n",
    "for n in range(3):\n",
    "  print(\"Original: \", example[n].numpy())\n",
    "  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print([layer.supports_masking for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00151565]\n"
     ]
    }
   ],
   "source": [
    "sample_text = ('The movie was cool. The animation and the graphics '\n",
    "               'were out of this world. I would recommend this movie.')\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 301s 755ms/step - loss: 0.6262 - accuracy: 0.5848 - val_loss: 0.4873 - val_accuracy: 0.7427\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 286s 732ms/step - loss: 0.4402 - accuracy: 0.7927 - val_loss: 0.3979 - val_accuracy: 0.8240\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 283s 723ms/step - loss: 0.3763 - accuracy: 0.8328 - val_loss: 0.3635 - val_accuracy: 0.8464\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 281s 719ms/step - loss: 0.3398 - accuracy: 0.8542 - val_loss: 0.3482 - val_accuracy: 0.8365\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 269s 688ms/step - loss: 0.3219 - accuracy: 0.8607 - val_loss: 0.3392 - val_accuracy: 0.8380\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 271s 693ms/step - loss: 0.3148 - accuracy: 0.8635 - val_loss: 0.3277 - val_accuracy: 0.8604\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 268s 687ms/step - loss: 0.3090 - accuracy: 0.8683 - val_loss: 0.3340 - val_accuracy: 0.8594\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 275s 702ms/step - loss: 0.3030 - accuracy: 0.8694 - val_loss: 0.3254 - val_accuracy: 0.8578\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 277s 707ms/step - loss: 0.3034 - accuracy: 0.8692 - val_loss: 0.3209 - val_accuracy: 0.8609\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 287s 733ms/step - loss: 0.2996 - accuracy: 0.8709 - val_loss: 0.3218 - val_accuracy: 0.8589\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=10,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: RNN/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: RNN/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fafd1298280> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fafd125cac0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save('RNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = ('The weather is great today')\n",
    "predictions = model.predict(np.array([sample_text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.058515]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
